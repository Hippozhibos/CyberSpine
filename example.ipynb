{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#@title Run to install MuJoCo and `dm_control`\n","import distutils.util\n","import os\n","import subprocess\n","if subprocess.run('nvidia-smi').returncode:\n","  raise RuntimeError(\n","      'Cannot communicate with GPU. '\n","      'Make sure you are using a GPU Colab runtime. '\n","      'Go to the Runtime menu and select Choose runtime type.')\n","\n","# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n","# This is usually installed as part of an Nvidia driver package, but the Colab\n","# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n","# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n","NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n","if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n","  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n","    f.write(\"\"\"{\n","    \"file_format_version\" : \"1.0.0\",\n","    \"ICD\" : {\n","        \"library_path\" : \"libEGL_nvidia.so.0\"\n","    }\n","}\n","\"\"\")\n","\n","# print('Installing dm_control...')\n","# !pip install -q dm_control>=1.0.18\n","\n","# Configure dm_control to use the EGL rendering backend (requires GPU)\n","%env MUJOCO_GL=egl\n","\n","print('Checking that the dm_control installation succeeded...')\n","try:\n","  from dm_control import suite\n","  env = suite.load('cartpole', 'swingup')\n","  pixels = env.physics.render()\n","except Exception as e:\n","  raise e from RuntimeError(\n","      'Something went wrong during installation. Check the shell output above '\n","      'for more information.\\n'\n","      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n","      'by going to the Runtime menu and selecting \"Choose runtime type\".')\n","else:\n","  del pixels, suite\n","\n","!echo Installed dm_control $(pip show dm_control | grep -Po \"(?<=Version: ).+\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#@title Other imports and helper functions\n","\n","# General\n","import copy\n","import os\n","import itertools\n","from IPython.display import clear_output\n","import numpy as np\n","\n","# Graphics-related\n","import matplotlib\n","import matplotlib.animation as animation\n","import matplotlib.pyplot as plt\n","from IPython.display import HTML\n","import PIL.Image\n","# Internal loading of video libraries.\n","\n","# Use svg backend for figure rendering\n","%config InlineBackend.figure_format = 'svg'\n","\n","# Font sizes\n","SMALL_SIZE = 8\n","MEDIUM_SIZE = 10\n","BIGGER_SIZE = 12\n","plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n","plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n","plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n","plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n","plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n","plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n","plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n","\n","# Inline video helper function\n","if os.environ.get('COLAB_NOTEBOOK_TEST', False):\n","  # We skip video generation during tests, as it is quite expensive.\n","  display_video = lambda *args, **kwargs: None\n","else:\n","  def display_video(frames, framerate=30):\n","    height, width, _ = frames[0].shape\n","    dpi = 70\n","\n","    orig_backend = matplotlib.get_backend()\n","    matplotlib.use('Agg')  # Switch to headless 'Agg' to inhibit figure rendering.\n","    fig, ax = plt.subplots(1, 1, figsize=(width / dpi, height / dpi), dpi=dpi)\n","    # fig, ax = plt.subplots(1, 1, figsize=(scaled_width / dpi, scaled_height / dpi), dpi=dpi)\n","    matplotlib.use(orig_backend)  # Switch back to the original backend.\n","    ax.set_axis_off()\n","    ax.set_aspect('equal')\n","    ax.set_position([0, 0, 1, 1])\n","    im = ax.imshow(frames[0])\n","    def update(frame):\n","      im.set_data(frame)\n","      return [im]\n","    interval = 1000/framerate\n","    anim = animation.FuncAnimation(fig=fig, func=update, frames=frames,\n","                                   interval=interval, blit=True, repeat=False)\n","    return HTML(anim.to_html5_video())\n","\n","# Seed numpy's global RNG so that cell outputs are deterministic. We also try to\n","# use RandomState instances that are local to a single cell wherever possible.\n","np.random.seed(42)"]},{"cell_type":"markdown","metadata":{},"source":["Define Environment"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","from dm_control import viewer\n","from env import mice_env\n","# from spine import prototype"]},{"cell_type":"markdown","metadata":{},"source":["Main Loop"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["env = mice_env.rodent_maze_forage()\n","action_spec = env.action_spec()\n","time_step = env.reset()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["frame_size = {'width': 640, 'height': 480}\n","pixels = env.physics.render(camera_id=1,**frame_size)\n","PIL.Image.fromarray(pixels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def random_policy(time_step):\n","    # Generates random actions within the specified range\n","    action = 0.01 * np.random.uniform(action_spec.minimum, action_spec.maximum,\n","                               size=action_spec.shape)\n","    # print(\"reward = {}, discount = {}, observations = {}.\".format(\n","    #   time_step.reward, time_step.discount, time_step.observation))\n","    return np.clip(action, action_spec.minimum, action_spec.maximum)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def PD_policy(time_step):\n","    # Access the current positions and velocities\n","    qpos = env.physics.data.qpos[7:]\n","    qvel = env.physics.data.qvel[6:]\n","\n","    # Define desired positions and velocities (for simplicity, assume you want to maintain the current position)\n","    desired_qpos = np.zeros_like(qpos)\n","    desired_qvel = np.zeros_like(qvel)\n","\n","    # Proportional-Derivative control gains\n","    Kp = 0.1\n","    Kd = 0.01\n","\n","    # PD control to compute actuator commands\n","    position_error = desired_qpos - qpos\n","    velocity_error = desired_qvel - qvel\n","    control_signal = 0.01*(Kp * position_error + Kd * velocity_error)\n","\n","    # Clip the control signal to the action specification limits\n","    action = np.clip(control_signal, action_spec.minimum, action_spec.maximum)\n","\n","    return action"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#@title Video of the movement{vertical-output: true}\n","#@test {\"timeout\": 600}\n","\n","duration = 10   # (Seconds)\n","framerate = 30  # (Hz)\n","video = []\n","\n","# Control signal frequency, phase, amplitude.\n","freq = 5\n","amp = 0.9\n","\n","# Initialize a list to store rewards.\n","rewards = []\n","discount = []\n","observation = []\n","\n","# Simulate, saving video frames and torso locations.\n","env.physics.reset()\n","while env.physics.data.time < duration:\n","  # Inject controls and step the physics.\n","  action = PD_policy(time_step)\n","  time_step = env.step(action)\n","\n","  # Store the reward\n","  rewards.append(time_step.reward)\n","  discount.append(time_step.discount)\n","  observation.append(time_step.observation)\n","  \n","  # print(\"reward = {}, discount = {}, observations = {}.\".format(\n","  #     time_step.reward, time_step.discount, time_step.observation))\n","\n","  # Save video frames.\n","  if len(video) < env.physics.data.time * framerate:\n","    pixels = env.physics.render(camera_id=1,**frame_size)\n","    video.append(pixels.copy())\n","\n","display_video(video, framerate)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# After the training loop, plot the rewards\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","\n","plt.plot(observation)\n","plt.title('Rewards over Time')\n","plt.xlabel('Time Step')\n","plt.ylabel('Reward')\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"mujoco","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":2}
