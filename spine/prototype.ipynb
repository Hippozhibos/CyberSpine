{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is mainly 2 group of neurons. 120 M neurons represents the motor neuron, their activity are transferred to muscle activity which activate 120 muscles in a musculoskeletal model in Mujoco. And then the muscle length observed in Mujoco.physics is transfered to 120 S neurons which represent the sensory neurons. The longer the muscles is, the higher the S neuron's activity is. At the beginning, the 120 M neurons have random relationships with each other. But with a rhythmic input to them, they were activated sequentially, and generate subtle movement in musculoskeletal model. Then the model feedback the muscle length to the sensory neuron. Because there are local circuits between S and M neurons, M neurons which have similar of opposite neurons would then have more and more related relationship. use Hebbian learning rule to update the neural network between S and M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangzhibo/anaconda3/envs/mujoco/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import mujoco as mj\n",
    "from mujoco.glfw import glfw\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "# print(torch.cuda.is_available())  # This should return True if GPU is enabled.\n",
    "# print(torch.cuda.get_device_name(0))  # Should print the name of your GPU.\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_path = r\"/home/zhangzhibo/CyberSpine/assets/CyberMice_CollisionGeom_JointActuated.xml\"\n",
    "simend = 5 #simulation time \n",
    "print_camera_config = 0 # set to 1 to print camera config\n",
    "                        # this is useful for initializing view of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for callback function\n",
    "button_left = False\n",
    "button_middle = False\n",
    "button_right = False\n",
    "lastx = 0\n",
    "lasty = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mj.MjModel.from_xml_path(xml_path) # MuJoCo model\n",
    "data = mj.MjData(model) # Mujoco data\n",
    "cam = mj.MjvCamera() # Abstruct camera\n",
    "opt = mj.MjvOption() # visualization options\n",
    "num_actuators = model.nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "print(num_actuators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder Component:\n",
    "1. Muscle Encoder:\n",
    "    Input: dim=120 muscle activity\n",
    "    Output: dim=32 muscle command\n",
    "2. Muscle Decoder:\n",
    "    Input: dim=32 muscle command \n",
    "    Output: dim=120 muscle activity\n",
    "3. Sensor Encoder:\n",
    "    Input: dim=120 sensor activity\n",
    "    Output: dim=32 sensor representation\n",
    "4. Sensor Decoder:\n",
    "    Input: dim=32 muscle representation\n",
    "    Output: dim=120 sensor activity\n",
    "\n",
    "Network Architecture:\n",
    "1. Muscle Autoencoder:\n",
    "    Components: Muscle Encoder + Muscle Decoder\n",
    "    Effects: Mapping between low-dim command and high-dim command\n",
    "    Shortage: Not biological plausible\n",
    "2. Sensor Autoencoder:\n",
    "    Components: Sensor Encoder + Sensor Decoder\n",
    "    Effects: Mapping between low-dim representation and high-dim activity\n",
    "    Shortage: Not biological plausible\n",
    "3. Kalman Estimator:\n",
    "    Components: Muscle Encoder + Sensor Decoder\n",
    "    Effects: Mapping muscle activity to sensory prediction; Use the error between S_est and S_true to update\n",
    "    Shortage: Seems not necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muscle Decoder:\n",
      "MuscleDecoder(\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=14, out_features=28, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=28, out_features=56, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Sensor Encoder:\n",
      "SensorEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=56, out_features=28, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=28, out_features=14, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Kalman Estimator:\n",
      "KalmanEstimator(\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=56, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=112, out_features=56, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "FullNetwork:\n",
      "FullNetwork(\n",
      "  (part1): MuscleDecoder(\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=14, out_features=28, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=28, out_features=56, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (part2): KalmanEstimator(\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=56, out_features=1024, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (7): ReLU()\n",
      "      (8): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (9): ReLU()\n",
      "      (10): Linear(in_features=112, out_features=56, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (part3): SensorEncoder(\n",
      "    (encoder): Sequential(\n",
      "      (0): Linear(in_features=56, out_features=28, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=28, out_features=14, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define Muscle Encoder\n",
    "class MuscleEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MuscleEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_actuators, int(num_actuators/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(num_actuators/2), int(num_actuators/4))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "# Define Muscle Decoder\n",
    "class MuscleDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MuscleDecoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(int(num_actuators/4), int(num_actuators/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(num_actuators/2), int(num_actuators))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "# Define Sensor Encoder\n",
    "class SensorEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SensorEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(int(num_actuators), int(num_actuators/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(num_actuators/2), int(num_actuators/4))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "# Define Sensor Decoder\n",
    "class SensorDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SensorDecoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(int(num_actuators/4), int(num_actuators/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(num_actuators/2), int(num_actuators))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "# Define Muscle Autoencoder\n",
    "class MuscleAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MuscleAutoencoder, self).__init__()\n",
    "        self.encoder = MuscleEncoder()\n",
    "        self.decoder = MuscleDecoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Define Sensor Autoencoder\n",
    "class SensorAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SensorAutoencoder, self).__init__()\n",
    "        self.encoder = SensorEncoder()\n",
    "        self.decoder = SensorDecoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    \n",
    "# Define KalmanEstimator\n",
    "class KalmanEstimator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KalmanEstimator, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(num_actuators, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_actuators*2, num_actuators)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "    \n",
    "class FullNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullNetwork, self).__init__()\n",
    "        self.part1 = MuscleDecoder()\n",
    "        self.part2 = KalmanEstimator()\n",
    "        self.part3 = SensorEncoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.part1(x)\n",
    "        x = self.part2(x)\n",
    "        x = self.part3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Test the autoencoder networks\n",
    "muscle_decoder = MuscleDecoder()\n",
    "sensor_encoder = SensorEncoder()\n",
    "kalman_estimator = KalmanEstimator()\n",
    "full_network = FullNetwork()\n",
    "\n",
    "# Print the architectures\n",
    "print(\"Muscle Decoder:\")\n",
    "print(muscle_decoder)\n",
    "print(\"\\nSensor Encoder:\")\n",
    "print(sensor_encoder)\n",
    "print(\"\\nKalman Estimator:\")\n",
    "print(kalman_estimator)\n",
    "print(\"\\nFullNetwork:\")\n",
    "print(full_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "muscle_optimizer = optim.Adam(muscle_decoder.parameters(), lr=0.001)\n",
    "sensor_optimizer = optim.Adam(sensor_encoder.parameters(), lr=0.001)\n",
    "kalman_optimizer = optim.Adam(kalman_estimator.parameters(), lr=0.001)\n",
    "full_network_optimizer = optim.Adam(full_network.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def controller (model,data):\n",
    "    pass\n",
    "    # num_actuators = model.na\n",
    "    # muscle_activation = np.zeros([num_actuators,1])\n",
    "\n",
    "    # muscle_length = data.actuator_length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24/03/31: \n",
    "1. Let's leave the biological plausity first. \n",
    "2. Only use 2 Autoencoders to learn correct mapping, these component could also be used to form kalman filter in the future. \n",
    "    2.1 The problem is: if only use 2 autoencoders, then the so called feedback would be unnecessary at all.\n",
    "    2.2 How do you use Hebbian Learning rule?\n",
    "3. The so called muscle synergy would come up in the decoder after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_torque_servo(actuator_no, flag):\n",
    "    if(flag==0):\n",
    "        model.actuator_gainprm[actuator_no, 0] = 0\n",
    "    else:\n",
    "        model.actuator_gainprm[actuator_no, 0] = 1\n",
    "\n",
    "def set_position_servo(actuator_no, kp):\n",
    "    model.actuator_gainprm[actuator_no,0] = kp\n",
    "    model.actuator_biasprm[actuator_no,1] = -kp\n",
    "\n",
    "def set_velocity_servo(actuator_no, kv):\n",
    "    model.actuator_gainprm[actuator_no,0] = kv\n",
    "    model.actuator_biasprm[actuator_no,2] = -kv   \n",
    "\n",
    "def keyboard(window, key, scancode, act, mods):\n",
    "    if act == glfw.PRESS and key == glfw.KEY_BACKSPACE:\n",
    "        mj.mj_resetData(model, data)\n",
    "        mj.mj_forward(model,data)\n",
    "\n",
    "def mouse_button(window, button, act, mods):\n",
    "    # update button state\n",
    "    global button_left\n",
    "    global button_middle\n",
    "    global button_right\n",
    "\n",
    "    button_left = (glfw.get_mouse_button(\n",
    "        window, glfw.MOUSE_BUTTON_LEFT) == glfw.PRESS)\n",
    "    button_middle = (glfw.get_mouse_button(\n",
    "        window, glfw.MOUSE_BUTTON_MIDDLE) == glfw.PRESS)\n",
    "    button_right = (glfw.get_mouse_button(\n",
    "        window, glfw.MOUSE_BUTTON_RIGHT) == glfw.PRESS)\n",
    "    \n",
    "    glfw.get_cursor_pos(window)\n",
    "\n",
    "def mouse_move(window, xpos, ypos):\n",
    "    # compute mouse displacement, save\n",
    "    global lastx\n",
    "    global lasty\n",
    "    global button_left\n",
    "    global button_middle\n",
    "    global button_right\n",
    "\n",
    "    dx = xpos - lastx\n",
    "    dy = ypos - lasty\n",
    "    lastx = xpos\n",
    "    lasty = ypos\n",
    "\n",
    "    # no button down: nothing to do\n",
    "    if (not button_left) and (not button_middle) and (not button_right):\n",
    "        return\n",
    "    \n",
    "    # get current window size\n",
    "    width, height = glfw.get_window_size(window)\n",
    "\n",
    "    # get shift key state\n",
    "    PRESS_LEFT_SHIFT = glfw.get_key(window, glfw.KEY_LEFT_SHIFT) == glfw.PRESS\n",
    "    PRESS_RIGHT_SHIFT = glfw.get_key(window, glfw.KEY_RIGHT_SHIFT) == glfw.PRESS\n",
    "    mod_shift = (PRESS_LEFT_SHIFT or PRESS_RIGHT_SHIFT)\n",
    "\n",
    "    # determine action based on mouse button\n",
    "    if button_right:\n",
    "        if mod_shift:\n",
    "            action = mj.mjtMouse.mjMOUSE_MOVE_H\n",
    "        else:\n",
    "            action = mj.mjtMouse.mjMOUSE_MOVE_V\n",
    "    elif button_left:\n",
    "        if mod_shift:\n",
    "            action = mj.mjtMouse.mjMOUSE_ROTATE_H\n",
    "        else:\n",
    "            action = mj.mjtMouse.mjMOUSE_ROTATE_V\n",
    "    else:\n",
    "        action = mj.mjtMouse.mjMOUSE_ZOOM\n",
    "\n",
    "    mj.mjv_moveCamera(model, action, dx/height, dy/height, scene, cam)\n",
    "\n",
    "def scroll(window, xoffset, yoffset):\n",
    "    action = mj.mjtMouse.mjMOUSE_ZOOM\n",
    "    mj.mjv_moveCamera(model, action, 0.0, -0.05 * yoffset, scene, cam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangzhibo/anaconda3/envs/mujoco/lib/python3.9/site-packages/glfw/__init__.py:914: GLFWError: (65544) b'X11: The DISPLAY environment variable is missing'\n",
      "  warnings.warn(message, GLFWError)\n",
      "/home/zhangzhibo/anaconda3/envs/mujoco/lib/python3.9/site-packages/glfw/__init__.py:914: GLFWError: (65537) b'The GLFW library is not initialized'\n",
      "  warnings.warn(message, GLFWError)\n"
     ]
    },
    {
     "ename": "FatalError",
     "evalue": "an OpenGL platform library has not been loaded into this process, this most likely means that a valid OpenGL context has not been created before mjr_makeContext was called",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFatalError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m mj\u001b[38;5;241m.\u001b[39mmjv_defaultOption(opt)\n\u001b[1;32m     10\u001b[0m scene \u001b[38;5;241m=\u001b[39m mj\u001b[38;5;241m.\u001b[39mMjvScene(model, maxgeom\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mmj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMjrContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmjtFontScale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmjFONTSCALE_150\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# install GLFW mouse and keyboard callbacks\u001b[39;00m\n\u001b[1;32m     14\u001b[0m glfw\u001b[38;5;241m.\u001b[39mset_key_callback(window, keyboard)\n",
      "\u001b[0;31mFatalError\u001b[0m: an OpenGL platform library has not been loaded into this process, this most likely means that a valid OpenGL context has not been created before mjr_makeContext was called"
     ]
    }
   ],
   "source": [
    "# Init GLFW, creat window, make OpenGL context current, request v-sync\n",
    "glfw.init()\n",
    "window = glfw.create_window(1200, 900, \"Demo\", None, None)\n",
    "glfw.make_context_current(window)\n",
    "glfw.swap_interval(1)\n",
    "\n",
    "# initialize visualization data structures\n",
    "mj.mjv_defaultCamera(cam)\n",
    "mj.mjv_defaultOption(opt)\n",
    "scene = mj.MjvScene(model, maxgeom=10000)\n",
    "context = mj.MjrContext(model, mj.mjtFontScale.mjFONTSCALE_150.value)\n",
    "\n",
    "# install GLFW mouse and keyboard callbacks\n",
    "glfw.set_key_callback(window, keyboard)\n",
    "glfw.set_cursor_pos_callback(window, mouse_move)\n",
    "glfw.set_mouse_button_callback(window, mouse_button)\n",
    "glfw.set_scroll_callback(window, scroll)\n",
    "\n",
    "# Example on how to set camera configuration\n",
    "# initialize the controller here. This function is called once, in the beginning\n",
    "cam.azimuth = 89.83044433593757 ; cam.elevation = -20 ; cam.distance = 15.04038754800176\n",
    "cam.lookat = np.array([0.0, 0.0, 0.0])\n",
    "\n",
    "# intialize the controller\n",
    "# init_controller(model, data)\n",
    "\n",
    "# set the controller\n",
    "mj.set_mjcb_control(controller)\n",
    "\n",
    "N = 100\n",
    "mj.mj_forward(model,data)\n",
    "\n",
    "# print(position_Q)\n",
    "\n",
    "i = 0\n",
    "time = 0\n",
    "dt =0.0025\n",
    "\n",
    "max_loss = 0.01\n",
    "muscle_losses = []  # List to store muscle autoencoder losses\n",
    "sensor_losses = []  # List to store sensor autoencoder losses\n",
    "kalman_losses = []\n",
    "full_network_losses=[]\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(N), desc=\"Simulation Progress\"):\n",
    "    time_prev = data.time\n",
    "    # time_prev = time\n",
    "\n",
    "    # Training loop\n",
    "    muscle_running_loss = 0.0\n",
    "    sensor_running_loss = 0.0\n",
    "    kalman_running_loss = 0.0\n",
    "    latent_state_running_loss = 0.0\n",
    "    epoch = 0\n",
    "\n",
    "    while (data.time - time_prev < 1.0/60.0):\n",
    "    # while (time - time_prev < 1.0/60.0):\n",
    "\n",
    "        # num_actuators = model.na\n",
    "        latent_muscle_activation = np.zeros([int(num_actuators/4)])\n",
    "        latent_muscle_activation[int(i%(num_actuators/4))] = 0.9\n",
    "        latent_muscle_activation = torch.tensor(latent_muscle_activation, dtype=torch.float32)\n",
    "\n",
    "        full_network_optimizer.zero_grad()\n",
    "        latent_state_est = full_network(latent_muscle_activation)\n",
    "\n",
    "        muscle_optimizer.zero_grad()\n",
    "        sensor_optimizer.zero_grad()\n",
    "        muscle_activation_est = muscle_decoder(latent_muscle_activation)\n",
    "        data.ctrl[:] = muscle_activation_est.detach().numpy()\n",
    "        mj.mj_step(model, data)\n",
    "        muscle_length = data.actuator_length\n",
    "        muscle_length = torch.tensor(muscle_length, dtype=torch.float32)\n",
    "        latent_state = sensor_encoder(muscle_length)\n",
    "\n",
    "        latent_state_loss = criterion(latent_state_est, latent_state)\n",
    "        latent_state_loss.backward()\n",
    "        full_network_optimizer.step()\n",
    "\n",
    "        if i%5 == 0:\n",
    "            muscle_decoder.load_state_dict(full_network.part1.state_dict())\n",
    "            sensor_encoder.load_state_dict(full_network.part3.state_dict())\n",
    "\n",
    "\n",
    "        latent_state_running_loss += latent_state_loss.item()\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    # Calculate average losses\n",
    "    # avg_muscle_loss = muscle_running_loss / i\n",
    "    # avg_sensor_loss = sensor_running_loss / i\n",
    "    # avg_kalman_loss = kalman_running_loss / i\n",
    "\n",
    "    # muscle_losses.append(avg_muscle_loss)  # Append muscle loss to the list\n",
    "    # sensor_losses.append(avg_sensor_loss)  # Append sensor loss to the list\n",
    "    # kalman_losses.append(avg_kalman_loss)\n",
    "    full_network_losses.append(latent_state_running_loss)\n",
    "\n",
    "    # print(f\"Epoch {epoch + 1}, Muscle Loss: {avg_muscle_loss}, Sensor Loss: {avg_sensor_loss}\")\n",
    "\n",
    "    # Check if the average loss is below the desired threshold\n",
    "    # if avg_muscle_loss < max_loss and avg_sensor_loss < max_loss and avg_kalman_loss < max_loss:\n",
    "        # print(\"Training stopped: Loss reached the desired threshold.\")\n",
    "        # break\n",
    "\n",
    "\n",
    "    # if (data.time>=simend):\n",
    "    #     plt.figure(1)\n",
    "    #     plt.subplot(2,1,1)\n",
    "    #     # plt.plot(t,qact0,'r-')\n",
    "    #     # plt.plot(t,qref0,'k');\n",
    "    #     plt.plot(t,np.subtract(qref0,qact0),'k')\n",
    "    #     plt.ylabel(\"error position joint 0\")\n",
    "    #     plt.subplot(2,1,2)\n",
    "    #     # plt.plot(t,qact1,'r-')\n",
    "    #     # plt.plot(t,qref1,'k');\n",
    "    #     plt.plot(t,np.subtract(qref1,qact1),'k')\n",
    "    #     plt.ylabel(\"error position joint 0\")\n",
    "    #     plt.show(block=False)\n",
    "    #     plt.pause(10)\n",
    "    #     plt.close()\n",
    "    #     break;\n",
    "\n",
    "    # get framebuffer viewport\n",
    "    viewport_width, viewport_height = glfw.get_framebuffer_size(window)\n",
    "    viewport = mj.MjrRect(0,0,viewport_width, viewport_height)\n",
    "\n",
    "    # print camera configuration (help to initialize the view)\n",
    "    if (print_camera_config==1):\n",
    "        print('cam.azimuth =', cam.azimuth,';','cam.elevation =',cam.elevation,';','cam.distance =',cam.distance)\n",
    "        print('cam.lookat = np.array([',cam.lookat[0],',',cam.lookat[1],',',cam.lookat[2],'])')\n",
    "\n",
    "    # Update scene and render\n",
    "    mj.mjv_updateScene(model, data, opt, None, cam,\n",
    "                       mj.mjtCatBit.mjCAT_ALL.value, scene)\n",
    "    mj.mjr_render(viewport, scene, context)\n",
    "\n",
    "    # swap OpenGL buffers (blocking call due to v-sync)\n",
    "    glfw.swap_buffers(window)\n",
    "\n",
    "    # process pending GUI events, call GLFW callbacks\n",
    "    glfw.poll_events()\n",
    "\n",
    "# Plot the losses after training\n",
    "# print(\"muscle_losses\", muscle_losses)\n",
    "# print(\"\\nsensor_losses\", sensor_losses)\n",
    "# print(\"\\nkalman_losses\", kalman_losses)\n",
    "print(\"\\nfull_network_losses\", full_network_losses)\n",
    "\n",
    "# plt.plot(muscle_losses, label='Muscle Autoencoder Loss')\n",
    "# plt.plot(sensor_losses, label='Sensor Autoencoder Loss')\n",
    "# plt.plot(kalman_losses, label='Kalman Estimator Loss')\n",
    "plt.plot(full_network_losses, label='full_network_losses')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Losses')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "glfw.terminate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
